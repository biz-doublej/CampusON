# PDF íŒŒì‹± ì•Œê³ ë¦¬ì¦˜ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” êµ­ê°€ì‹œí—˜ ë¬¸ì œì§€ PDFì—ì„œ ë¬¸ì œ, ì„ íƒì§€, ì •ë‹µì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ê³¼ íŒ¨í„´ ì¸ì‹ ê¸°ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ” PDF ë¬¸ì„œ ë¶„ì„

### ì¼ë°˜ì ì¸ êµ­ê°€ì‹œí—˜ PDF êµ¬ì¡°

```
[í‘œì§€/ì œëª© ì˜ì—­]
2023ë…„ë„ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ êµ­ê°€ì‹œí—˜ ë¬¸ì œì§€

[ë¬¸ì œ ì˜ì—­]
1. ë‹¤ìŒ ì¤‘ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ì˜ ì—­í• ë¡œ ê°€ì¥ ì ì ˆí•œ ê²ƒì€?
   1) í™˜ìì˜ ì§„ë‹¨ì„ ë‚´ë¦¬ëŠ” ê²ƒ
   2) í™˜ìì˜ ì¬í™œì„ ë•ëŠ” ê²ƒ
   3) ì•½ë¬¼ì„ ì²˜ë°©í•˜ëŠ” ê²ƒ
   4) ìˆ˜ìˆ ì„ ì§‘ë„í•˜ëŠ” ê²ƒ
   5) ì˜ë£Œê¸°ê¸°ë¥¼ íŒë§¤í•˜ëŠ” ê²ƒ

2. ê·¼ìœ¡ì˜ ì£¼ìš” ê¸°ëŠ¥ì´ ì•„ë‹Œ ê²ƒì€?
   â‘  ì²´ì˜¨ ì¡°ì ˆ
   â‘¡ ìì„¸ ìœ ì§€
   â‘¢ í˜ˆì•¡ ìˆœí™˜
   â‘£ ê´€ì ˆ ì›€ì§ì„
   â‘¤ í˜¸ë¥´ëª¬ ë¶„ë¹„

[ì •ë‹µ ì˜ì—­ - ë¬¸ì„œ ë§ˆì§€ë§‰ ë˜ëŠ” ë³„ë„ í˜ì´ì§€]
ì •ë‹µ
1ë²ˆ: 2
2ë²ˆ: â‘¤
```

### íŒ¨í„´ ë¶„ì„

#### 1. ë¬¸ì œ ë²ˆí˜¸ íŒ¨í„´
```python
# ë‹¤ì–‘í•œ ë¬¸ì œ ë²ˆí˜¸ í˜•ì‹
patterns = [
    r'^(\d+)\.\s*',      # "1. ë¬¸ì œë‚´ìš©"
    r'^(\d+)\)\s*',      # "1) ë¬¸ì œë‚´ìš©"  
    r'^ë¬¸ì œ\s*(\d+)',    # "ë¬¸ì œ 1"
    r'^(\d+)ë²ˆ',         # "1ë²ˆ"
]

# ì˜ˆì œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
sample_texts = [
    "1. ë‹¤ìŒ ì¤‘ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ì˜ ì—­í• ì€?",
    "2) ê·¼ìœ¡ì˜ ê¸°ëŠ¥ì´ ì•„ë‹Œ ê²ƒì€?",
    "ë¬¸ì œ 3. ê´€ì ˆì˜ ì¢…ë¥˜ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ",
    "4ë²ˆ. ë¼ˆì˜ êµ¬ì¡°ì—ì„œ"
]
```

#### 2. ì„ íƒì§€ íŒ¨í„´
```python
# ì„ íƒì§€ í˜•ì‹ë“¤
option_patterns = {
    'numeric_paren': r'^(\d+)\)\s*(.+)$',           # "1) ë‚´ìš©"
    'circle_numbers': r'^([â‘ -â‘¤])\s*(.+)$',          # "â‘  ë‚´ìš©"
    'korean_letters': r'^([ê°€-ë§ˆ])\.\s*(.+)$',      # "ê°€. ë‚´ìš©"
    'parentheses': r'^\((\d+)\)\s*(.+)$',          # "(1) ë‚´ìš©"
    'alphabet': r'^([A-E])\.\s*(.+)$',             # "A. ë‚´ìš©"
}

# ì„ íƒì§€ ë³€í™˜ ë§¤í•‘
def normalize_option_key(key: str) -> str:
    """ì„ íƒì§€ í‚¤ë¥¼ ìˆ«ìë¡œ í‘œì¤€í™”"""
    mappings = {
        'â‘ ': '1', 'â‘¡': '2', 'â‘¢': '3', 'â‘£': '4', 'â‘¤': '5',
        'ê°€': '1', 'ë‚˜': '2', 'ë‹¤': '3', 'ë¼': '4', 'ë§ˆ': '5',
        'A': '1', 'B': '2', 'C': '3', 'D': '4', 'E': '5',
    }
    return mappings.get(key, key)
```

#### 3. ì •ë‹µ íŒ¨í„´
```python
# ì •ë‹µ ì„¹ì…˜ íŒ¨í„´ë“¤
answer_patterns = [
    r'ì •ë‹µ[\s:]*(.*?)(?=\n\n|\Z)',                    # "ì •ë‹µ: 1, 2, 3..."
    r'í•´ë‹µ[\s:]*(.*?)(?=\n\n|\Z)',                    # "í•´ë‹µ: 1, 2, 3..."
    r'(\d+)ë²ˆ?\s*[:\.]\s*([â‘ -â‘¤]|\d+|[ê°€-ë§ˆ])',        # "1ë²ˆ: â‘¡"
    r'(\d+)\s*[-\.\)]\s*([â‘ -â‘¤]|\d+|[ê°€-ë§ˆ])',        # "1 - â‘¡"
]
```

## ğŸ¤– íŒŒì‹± ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

### 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬

```python
import re
from typing import List, Dict, Tuple

def preprocess_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    
    # 1. ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\n\s*\n', '\n\n', text)
    
    # 2. íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
    text = text.replace('\r', '\n')
    text = text.replace('\t', ' ')
    
    # 3. í˜ì´ì§€ ë²ˆí˜¸, í—¤ë”/í‘¸í„° ì œê±°
    text = re.sub(r'- \d+ -', '', text)  # í˜ì´ì§€ ë²ˆí˜¸
    text = re.sub(r'^\d+/\d+$', '', text, flags=re.MULTILINE)  # "1/50" í˜•ì‹
    
    # 4. ë°˜ë³µë˜ëŠ” ì œëª© ì œê±°
    lines = text.split('\n')
    unique_lines = []
    seen_lines = set()
    
    for line in lines:
        clean_line = line.strip()
        if clean_line and clean_line not in seen_lines:
            unique_lines.append(line)
            seen_lines.add(clean_line)
        elif not clean_line:
            unique_lines.append(line)
    
    return '\n'.join(unique_lines)

def extract_text_by_sections(pdf_path: str) -> Dict[str, str]:
    """PDFë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    import pdfplumber
    
    sections = {
        'title': '',
        'questions': '',
        'answers': ''
    }
    
    with pdfplumber.open(pdf_path) as pdf:
        all_text = ""
        
        for page_num, page in enumerate(pdf.pages):
            page_text = page.extract_text() or ""
            
            # ì²« í˜ì´ì§€ëŠ” ì œëª© ì •ë³´ í¬í•¨ ê°€ëŠ¥ì„± ë†’ìŒ
            if page_num == 0:
                sections['title'] += page_text[:500]  # ì²« 500ì
            
            all_text += page_text + "\n"
        
        # ì •ë‹µ ì„¹ì…˜ ë¶„ë¦¬ (ë³´í†µ ë¬¸ì„œ í›„ë°˜ë¶€)
        answer_match = re.search(r'(ì •ë‹µ|í•´ë‹µ|ë‹µì•ˆ).*', all_text, re.DOTALL | re.IGNORECASE)
        if answer_match:
            answer_start = answer_match.start()
            sections['questions'] = all_text[:answer_start]
            sections['answers'] = all_text[answer_start:]
        else:
            sections['questions'] = all_text
    
    return sections
```

### 2. ì§€ëŠ¥í˜• ë¬¸ì œ ì¶”ì¶œ

```python
class IntelligentQuestionExtractor:
    def __init__(self):
        self.question_patterns = [
            re.compile(r'^(\d+)\.\s*(.+?)(?=\n\s*\d+\.|$)', re.MULTILINE | re.DOTALL),
            re.compile(r'^(\d+)\)\s*(.+?)(?=\n\s*\d+\)|$)', re.MULTILINE | re.DOTALL),
            re.compile(r'ë¬¸ì œ\s*(\d+)[\.:]?\s*(.+?)(?=ë¬¸ì œ\s*\d+|$)', re.MULTILINE | re.DOTALL),
        ]
        
        self.option_patterns = [
            re.compile(r'^\s*(\d+)\)\s*(.+?)(?=\n\s*\d+\)|$)', re.MULTILINE),
            re.compile(r'^\s*([â‘ -â‘¤])\s*(.+?)(?=\n\s*[â‘ -â‘¤]|$)', re.MULTILINE),
            re.compile(r'^\s*([ê°€-ë§ˆ])\.\s*(.+?)(?=\n\s*[ê°€-ë§ˆ]\.|$)', re.MULTILINE),
        ]

    def extract_questions_advanced(self, text: str) -> List[Dict]:
        """ê³ ê¸‰ ë¬¸ì œ ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜"""
        questions = []
        
        # 1ë‹¨ê³„: ë¬¸ì œ ë¸”ë¡ ë¶„ë¦¬
        question_blocks = self._split_into_question_blocks(text)
        
        for block in question_blocks:
            try:
                question_data = self._parse_question_block(block)
                if question_data:
                    questions.append(question_data)
            except Exception as e:
                print(f"ë¬¸ì œ ë¸”ë¡ íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
        
        return questions

    def _split_into_question_blocks(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì œ ë¸”ë¡ìœ¼ë¡œ ë¶„ë¦¬"""
        
        # ê°€ì¥ ì í•©í•œ íŒ¨í„´ ì°¾ê¸°
        best_pattern = None
        max_matches = 0
        
        for pattern in self.question_patterns:
            matches = pattern.findall(text)
            if len(matches) > max_matches:
                max_matches = len(matches)
                best_pattern = pattern
        
        if not best_pattern:
            return []
        
        # íŒ¨í„´ìœ¼ë¡œ ë¶„ë¦¬
        splits = best_pattern.split(text)
        blocks = []
        
        for i in range(1, len(splits), 3):
            if i + 1 < len(splits):
                question_num = splits[i]
                question_content = splits[i + 1]
                blocks.append(f"{question_num}. {question_content}")
        
        return blocks

    def _parse_question_block(self, block: str) -> Dict:
        """ê°œë³„ ë¬¸ì œ ë¸”ë¡ì„ íŒŒì‹±"""
        lines = block.split('\n')
        
        # ë¬¸ì œ ë²ˆí˜¸ ì¶”ì¶œ
        first_line = lines[0].strip()
        number_match = re.match(r'^(\d+)', first_line)
        if not number_match:
            return None
        
        question_num = int(number_match.group(1))
        
        # ë¬¸ì œ ë‚´ìš©ê³¼ ì„ íƒì§€ ë¶„ë¦¬
        content_lines = []
        option_lines = []
        
        in_options = False
        
        for line in lines[1:]:
            line = line.strip()
            if not line:
                continue
            
            # ì„ íƒì§€ ì‹œì‘ ê°ì§€
            is_option = False
            for pattern in self.option_patterns:
                if pattern.match(line):
                    is_option = True
                    in_options = True
                    break
            
            if is_option or in_options:
                option_lines.append(line)
            else:
                content_lines.append(line)
        
        # ë¬¸ì œ ë‚´ìš© ì •ì œ
        content = ' '.join(content_lines).strip()
        content = self._clean_question_content(content)
        
        # ì„ íƒì§€ íŒŒì‹±
        options = self._parse_options(option_lines)
        
        return {
            'number': question_num,
            'content': content,
            'options': options
        }

    def _clean_question_content(self, content: str) -> str:
        """ë¬¸ì œ ë‚´ìš©ì„ ì •ì œí•©ë‹ˆë‹¤."""
        
        # ì¼ë°˜ì ì¸ ë¶ˆí•„ìš”í•œ íŒ¨í„´ ì œê±°
        patterns_to_remove = [
            r'^\d+\.\s*',  # ë¬¸ì œ ë²ˆí˜¸
            r'ë¬¸ì œ\s*\d+\s*[\.:]?\s*',  # "ë¬¸ì œ 1."
            r'\[.*?\]',  # ëŒ€ê´„í˜¸ ì•ˆì˜ ë‚´ìš©
            r'\(ë‹¨,.*?\)',  # ì¡°ê±´ ì„¤ëª…
        ]
        
        for pattern in patterns_to_remove:
            content = re.sub(pattern, '', content, flags=re.IGNORECASE)
        
        # ê³µë°± ì •ë¦¬
        content = re.sub(r'\s+', ' ', content).strip()
        
        return content

    def _parse_options(self, option_lines: List[str]) -> Dict[str, str]:
        """ì„ íƒì§€ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        options = {}
        
        for line in option_lines:
            for pattern in self.option_patterns:
                match = pattern.match(line)
                if match:
                    key = self._normalize_option_key(match.group(1))
                    value = match.group(2).strip()
                    options[key] = value
                    break
        
        return options

    def _normalize_option_key(self, key: str) -> str:
        """ì„ íƒì§€ í‚¤ë¥¼ í‘œì¤€í™”"""
        mapping = {
            'â‘ ': '1', 'â‘¡': '2', 'â‘¢': '3', 'â‘£': '4', 'â‘¤': '5',
            'ê°€': '1', 'ë‚˜': '2', 'ë‹¤': '3', 'ë¼': '4', 'ë§ˆ': '5',
        }
        return mapping.get(key, key)
```

### 3. ì •ë‹µ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜

```python
class AnswerMatcher:
    def __init__(self):
        self.answer_patterns = [
            # "1ë²ˆ: 2" í˜•íƒœ
            re.compile(r'(\d+)ë²ˆ?\s*[:\.]\s*([â‘ -â‘¤]|\d+|[ê°€-ë§ˆ])', re.MULTILINE),
            # "1. â‘¡" í˜•íƒœ  
            re.compile(r'(\d+)\.\s*([â‘ -â‘¤]|\d+|[ê°€-ë§ˆ])', re.MULTILINE),
            # "1-2" í˜•íƒœ
            re.compile(r'(\d+)\s*[-â€“]\s*([â‘ -â‘¤]|\d+|[ê°€-ë§ˆ])', re.MULTILINE),
            # í‘œ í˜•íƒœ (íƒ­ êµ¬ë¶„)
            re.compile(r'(\d+)\s+([â‘ -â‘¤]|\d+|[ê°€-ë§ˆ])', re.MULTILINE),
        ]

    def extract_answers(self, answer_text: str) -> Dict[int, str]:
        """ì •ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ì •ë‹µì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        answers = {}
        
        # ì •ë‹µ ì„¹ì…˜ ì •ì œ
        answer_text = self._clean_answer_section(answer_text)
        
        # ê° íŒ¨í„´ìœ¼ë¡œ ì‹œë„
        for pattern in self.answer_patterns:
            matches = pattern.findall(answer_text)
            
            for question_num, answer in matches:
                try:
                    num = int(question_num)
                    normalized_answer = self._normalize_answer(answer)
                    if normalized_answer:
                        answers[num] = normalized_answer
                except ValueError:
                    continue
        
        return answers

    def _clean_answer_section(self, text: str) -> str:
        """ì •ë‹µ ì„¹ì…˜ì„ ì •ì œí•©ë‹ˆë‹¤."""
        
        # ì •ë‹µ ì„¹ì…˜ ì‹œì‘ì  ì°¾ê¸°
        start_patterns = [
            r'ì •ë‹µ',
            r'í•´ë‹µ', 
            r'ë‹µì•ˆ',
            r'ì •í•´',
            r'Answer'
        ]
        
        for pattern in start_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                text = text[match.start():]
                break
        
        # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        text = re.sub(r'í•´ì„¤.*', '', text, flags=re.DOTALL)  # í•´ì„¤ ë¶€ë¶„ ì œê±°
        text = re.sub(r'ë¬¸ì œ.*?ì •ë‹µ', 'ì •ë‹µ', text, flags=re.DOTALL)
        
        return text

    def _normalize_answer(self, answer: str) -> str:
        """ì •ë‹µì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        mapping = {
            'â‘ ': '1', 'â‘¡': '2', 'â‘¢': '3', 'â‘£': '4', 'â‘¤': '5',
            'ê°€': '1', 'ë‚˜': '2', 'ë‹¤': '3', 'ë¼': '4', 'ë§ˆ': '5',
        }
        return mapping.get(answer, answer)

    def match_answers_to_questions(self, questions: List[Dict], answers: Dict[int, str]):
        """ì •ë‹µì„ ë¬¸ì œì— ë§¤ì¹­í•©ë‹ˆë‹¤."""
        for question in questions:
            question_num = question.get('number')
            if question_num in answers:
                question['answer'] = answers[question_num]
```

## ğŸ”§ í’ˆì§ˆ í–¥ìƒ ê¸°ë²•

### 1. ì‹ ë¢°ë„ ê²€ì¦

```python
class QualityValidator:
    def validate_parsing_result(self, questions: List[Dict]) -> Dict[str, float]:
        """íŒŒì‹± ê²°ê³¼ì˜ í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        
        scores = {
            'completeness': self._check_completeness(questions),
            'consistency': self._check_consistency(questions),
            'format_validity': self._check_format_validity(questions)
        }
        
        scores['overall'] = sum(scores.values()) / len(scores)
        return scores

    def _check_completeness(self, questions: List[Dict]) -> float:
        """ì™„ì„±ë„ ê²€ì‚¬"""
        if not questions:
            return 0.0
        
        complete_questions = 0
        for q in questions:
            if (q.get('content') and 
                q.get('options') and 
                len(q.get('options', {})) >= 2):
                complete_questions += 1
        
        return complete_questions / len(questions)

    def _check_consistency(self, questions: List[Dict]) -> float:
        """ì¼ê´€ì„± ê²€ì‚¬"""
        if len(questions) < 2:
            return 1.0
        
        # ë¬¸ì œ ë²ˆí˜¸ ì—°ì†ì„± í™•ì¸
        numbers = [q.get('number', 0) for q in questions]
        numbers.sort()
        
        expected = list(range(numbers[0], numbers[0] + len(numbers)))
        consistency = sum(1 for a, b in zip(numbers, expected) if a == b) / len(numbers)
        
        return consistency

    def _check_format_validity(self, questions: List[Dict]) -> float:
        """í˜•ì‹ ìœ íš¨ì„± ê²€ì‚¬"""
        valid_questions = 0
        
        for q in questions:
            is_valid = True
            
            # ë¬¸ì œ ë‚´ìš© ê¸¸ì´ ê²€ì‚¬
            content = q.get('content', '')
            if len(content) < 10 or len(content) > 1000:
                is_valid = False
            
            # ì„ íƒì§€ ê°œìˆ˜ ê²€ì‚¬
            options = q.get('options', {})
            if len(options) < 2 or len(options) > 6:
                is_valid = False
            
            # ì„ íƒì§€ í‚¤ í˜•ì‹ ê²€ì‚¬
            for key in options.keys():
                if not re.match(r'^[1-6]$', str(key)):
                    is_valid = False
            
            if is_valid:
                valid_questions += 1
        
        return valid_questions / len(questions) if questions else 0.0
```

### 2. ì˜¤ë¥˜ ë³µêµ¬ ë° ë³´ì •

```python
class ErrorRecovery:
    def auto_correct_questions(self, questions: List[Dict]) -> List[Dict]:
        """ìë™ ì˜¤ë¥˜ ë³´ì •"""
        corrected = []
        
        for q in questions:
            corrected_q = self._correct_single_question(q)
            if corrected_q:
                corrected.append(corrected_q)
        
        # ë¬¸ì œ ë²ˆí˜¸ ì¬ì •ë ¬
        corrected = self._renumber_questions(corrected)
        
        return corrected

    def _correct_single_question(self, question: Dict) -> Dict:
        """ê°œë³„ ë¬¸ì œ ë³´ì •"""
        q = question.copy()
        
        # ë¬¸ì œ ë‚´ìš© ë³´ì •
        content = q.get('content', '')
        content = self._clean_question_content(content)
        q['content'] = content
        
        # ì„ íƒì§€ ë³´ì •
        options = q.get('options', {})
        corrected_options = {}
        
        for key, value in options.items():
            # í‚¤ ì •ê·œí™”
            normalized_key = re.sub(r'[^\d]', '', str(key))
            if normalized_key and normalized_key.isdigit():
                # ê°’ ì •ì œ
                clean_value = re.sub(r'^\s*[^\w]*\s*', '', value)
                corrected_options[normalized_key] = clean_value
        
        q['options'] = corrected_options
        
        return q if corrected_options else None

    def _renumber_questions(self, questions: List[Dict]) -> List[Dict]:
        """ë¬¸ì œ ë²ˆí˜¸ ì¬ì •ë ¬"""
        for i, q in enumerate(questions, 1):
            q['number'] = i
        return questions
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### ë©€í‹°í”„ë¡œì„¸ì‹± í™œìš©

```python
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor
import time

class PerformanceOptimizer:
    def __init__(self, max_workers=None):
        self.max_workers = max_workers or mp.cpu_count()

    def parallel_page_extraction(self, pdf_path: str) -> List[str]:
        """í˜ì´ì§€ë³„ ë³‘ë ¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        import pdfplumber
        
        with pdfplumber.open(pdf_path) as pdf:
            page_count = len(pdf.pages)
            
            # í˜ì´ì§€ ë‹¨ìœ„ë¡œ ë¶„í• 
            page_ranges = [(i, i+1) for i in range(page_count)]
            
            with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
                page_texts = list(executor.map(
                    self._extract_page_range,
                    [(pdf_path, start, end) for start, end in page_ranges]
                ))
            
            return page_texts

    def _extract_page_range(self, args: tuple) -> str:
        """í˜ì´ì§€ ë²”ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        pdf_path, start, end = args
        
        import pdfplumber
        text = ""
        
        with pdfplumber.open(pdf_path) as pdf:
            for i in range(start, min(end, len(pdf.pages))):
                page_text = pdf.pages[i].extract_text() or ""
                text += page_text + "\n"
        
        return text

    def cached_pattern_matching(self, text: str, patterns: List[str]) -> Dict:
        """íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼ ìºì‹±"""
        import hashlib
        import pickle
        import os
        
        # í…ìŠ¤íŠ¸ í•´ì‹œ ìƒì„±
        text_hash = hashlib.md5(text.encode()).hexdigest()
        cache_file = f"/tmp/pattern_cache_{text_hash}.pkl"
        
        # ìºì‹œ í™•ì¸
        if os.path.exists(cache_file):
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        
        # íŒ¨í„´ ë§¤ì¹­ ìˆ˜í–‰
        results = {}
        for pattern in patterns:
            results[pattern] = re.findall(pattern, text, re.MULTILINE)
        
        # ê²°ê³¼ ìºì‹±
        with open(cache_file, 'wb') as f:
            pickle.dump(results, f)
        
        return results
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

### ë‹¤ì–‘í•œ PDF í˜•ì‹ í…ŒìŠ¤íŠ¸

```python
test_cases = [
    {
        'name': 'í‘œì¤€ êµ­ê°€ì‹œí—˜ í˜•ì‹',
        'description': 'ì¼ë°˜ì ì¸ 5ì§€ì„ ë‹¤í˜•',
        'sample_text': '''
        1. ë‹¤ìŒ ì¤‘ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ì˜ ì—­í• ì€?
        1) ì§„ë‹¨
        2) ì¬í™œ  
        3) ì²˜ë°©
        4) ìˆ˜ìˆ 
        5) íŒë§¤
        '''
    },
    {
        'name': 'ì›ë¬¸ì ì„ íƒì§€',
        'description': 'â‘ â‘¡â‘¢â‘£â‘¤ í˜•ì‹',
        'sample_text': '''
        1. ê·¼ìœ¡ì˜ ê¸°ëŠ¥ì´ ì•„ë‹Œ ê²ƒì€?
        â‘  ì›€ì§ì„
        â‘¡ ì§€ì§€
        â‘¢ ì†Œí™”
        â‘£ ì—´ìƒì‚°
        â‘¤ ë³´í˜¸
        '''
    },
    {
        'name': 'í•œê¸€ ì„ íƒì§€',
        'description': 'ê°€ë‚˜ë‹¤ë¼ë§ˆ í˜•ì‹',
        'sample_text': '''
        1. ì˜¬ë°”ë¥¸ ê²ƒì„ ê³ ë¥´ì‹œì˜¤.
        ê°€. ì²«ë²ˆì§¸ ì„ íƒì§€
        ë‚˜. ë‘ë²ˆì§¸ ì„ íƒì§€
        ë‹¤. ì„¸ë²ˆì§¸ ì„ íƒì§€
        ë¼. ë„¤ë²ˆì§¸ ì„ íƒì§€
        ë§ˆ. ë‹¤ì„¯ë²ˆì§¸ ì„ íƒì§€
        '''
    }
]
```

---

ì´ ì•Œê³ ë¦¬ì¦˜ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ì–‘í•œ PDF í˜•ì‹ì— ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” ê²¬ê³ í•œ íŒŒì„œë¥¼ ê°œë°œí•˜ì„¸ìš”! 