# íŒŒì„œ ê°œë°œ ê°€ì´ë“œ

## ğŸš€ ì‹œì‘í•˜ê¸°

ì´ ê°€ì´ë“œëŠ” CampusON íŒŒì„œ APIë¥¼ ê°œë°œí•˜ëŠ” ë°±ì—”ë“œ ê°œë°œìë¥¼ ìœ„í•œ ì‹¤ìš©ì ì¸ ê°œë°œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
backend/python-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ parse_models.py     # ë°ì´í„° ëª¨ë¸ ì •ì˜
â”‚   â”‚   â””â”€â”€ response_models.py  # API ì‘ë‹µ ëª¨ë¸
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ parser_service.py   # íŒŒì‹± ë¡œì§
â”‚   â”‚   â”œâ”€â”€ file_service.py     # íŒŒì¼ ì²˜ë¦¬
â”‚   â”‚   â””â”€â”€ ai_service.py       # AI í•´ì„¤ ìƒì„± (ì„ íƒì‚¬í•­)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ parser.py       # íŒŒì„œ API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”‚   â”‚   â””â”€â”€ results.py      # ê²°ê³¼ ì¡°íšŒ API
â”‚   â”‚   â””â”€â”€ dependencies.py     # ì˜ì¡´ì„± ì£¼ì…
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py          # ì„¤ì • ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ exceptions.py      # ì»¤ìŠ¤í…€ ì˜ˆì™¸
â”‚   â”‚   â””â”€â”€ logging.py         # ë¡œê¹… ì„¤ì •
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ file_utils.py      # íŒŒì¼ ìœ í‹¸ë¦¬í‹°
â”‚       â””â”€â”€ text_utils.py      # í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_parser.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_files/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

## ğŸ”§ í•µì‹¬ êµ¬í˜„

### 1. FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •

**`app/main.py`**
```python
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from app.api.endpoints import parser, results
from app.core.config import settings
from app.core.logging import setup_logging

# ë¡œê¹… ì„¤ì •
setup_logging()

app = FastAPI(
    title="CampusON Parser API",
    description="PDF ë¬¸ì œ íŒŒì‹± API",
    version="1.0.0",
    docs_url="/docs" if settings.DEBUG else None,
    redoc_url="/redoc" if settings.DEBUG else None,
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í˜¸ìŠ¤íŠ¸ ì„¤ì •
app.add_middleware(
    TrustedHostMiddleware, 
    allowed_hosts=settings.ALLOWED_HOSTS
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(parser.router, prefix="/api", tags=["parser"])
app.include_router(results.router, prefix="/api", tags=["results"])

@app.get("/api/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=settings.PORT)
```

### 2. ë°ì´í„° ëª¨ë¸ ì •ì˜

**`app/models/parse_models.py`**
```python
from pydantic import BaseModel, Field
from typing import Dict, List, Optional
from datetime import datetime

class ParsedQuestion(BaseModel):
    number: int = Field(..., description="ë¬¸ì œ ë²ˆí˜¸")
    content: str = Field(..., description="ë¬¸ì œ ë‚´ìš©")
    options: Dict[str, str] = Field(..., description="ì„ íƒì§€")
    answer: Optional[str] = Field(None, description="ì •ë‹µ")
    explanation: Optional[str] = Field(None, description="í•´ì„¤")

class ParsedMetadata(BaseModel):
    title: Optional[str] = Field(None, description="ì‹œí—˜ ì œëª©")
    year: Optional[int] = Field(None, description="ì‹œí—˜ ì—°ë„")
    subject: Optional[str] = Field(None, description="ê³¼ëª©ëª…")
    totalQuestions: Optional[int] = Field(None, description="ì „ì²´ ë¬¸ì œ ìˆ˜")

class ParsedResult(BaseModel):
    questions: List[ParsedQuestion] = Field(..., description="íŒŒì‹±ëœ ë¬¸ì œ ëª©ë¡")
    metadata: Optional[ParsedMetadata] = Field(None, description="ë©”íƒ€ë°ì´í„°")

class ParseJob(BaseModel):
    id: str
    status: str  # pending, processing, completed, failed
    result: Optional[ParsedResult] = None
    error: Optional[str] = None
    created_at: datetime
    completed_at: Optional[datetime] = None
```

### 3. íŒŒì‹± ì„œë¹„ìŠ¤ êµ¬í˜„

**`app/services/parser_service.py`**
```python
import re
import logging
from typing import List, Dict, Optional, Tuple
import pdfplumber
from app.models.parse_models import ParsedQuestion, ParsedResult, ParsedMetadata
from app.core.exceptions import ParsingError

logger = logging.getLogger(__name__)

class PDFParserService:
    def __init__(self):
        # ë¬¸ì œ ë²ˆí˜¸ íŒ¨í„´ (1., 2., 3. ë˜ëŠ” 1) 2) 3))
        self.question_pattern = re.compile(r'^(\d+)[\.\)]', re.MULTILINE)
        
        # ì„ íƒì§€ íŒ¨í„´ (1), 2), 3) ë˜ëŠ” â‘ , â‘¡, â‘¢)
        self.option_patterns = [
            re.compile(r'^(\d+)\)\s*(.+)$', re.MULTILINE),
            re.compile(r'^([â‘ -â‘¤])\s*(.+)$', re.MULTILINE),
            re.compile(r'^([ê°€-ë§ˆ])\.\s*(.+)$', re.MULTILINE),
        ]
        
        # ì •ë‹µ íŒ¨í„´
        self.answer_pattern = re.compile(r'ì •ë‹µ[\s:]*(\d+|[â‘ -â‘¤]|[ê°€-ë§ˆ])', re.IGNORECASE)

    async def parse_pdf(self, file_path: str) -> ParsedResult:
        """PDF íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë¬¸ì œì™€ ì„ íƒì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            with pdfplumber.open(file_path) as pdf:
                # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                full_text = ""
                for page in pdf.pages:
                    full_text += page.extract_text() or ""
                
                # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                metadata = self._extract_metadata(full_text, pdf)
                
                # ë¬¸ì œ ì¶”ì¶œ
                questions = self._extract_questions(full_text)
                
                # ì •ë‹µ ì¶”ì¶œ (ë³„ë„ ì„¹ì…˜ì— ìˆëŠ” ê²½ìš°)
                answers = self._extract_answers(full_text)
                
                # ì •ë‹µì„ ë¬¸ì œì— ë§¤í•‘
                self._map_answers_to_questions(questions, answers)
                
                return ParsedResult(
                    questions=questions,
                    metadata=metadata
                )
                
        except Exception as e:
            logger.error(f"PDF íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            raise ParsingError(f"PDF íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    def _extract_metadata(self, text: str, pdf) -> ParsedMetadata:
        """PDFì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        metadata = ParsedMetadata()
        
        # ì—°ë„ ì¶”ì¶œ (2023ë…„ë„, 2023ë…„ ë“±)
        year_match = re.search(r'(\d{4})ë…„', text)
        if year_match:
            metadata.year = int(year_match.group(1))
        
        # ê³¼ëª©ëª… ì¶”ì¶œ (ì¼ë°˜ì ì¸ ê³¼ëª©ëª… íŒ¨í„´)
        subject_patterns = [
            r'([ê°€-í£]+í•™)\s*êµ­ê°€ì‹œí—˜',
            r'([ê°€-í£]+ì¹˜ë£Œ)\s*êµ­ê°€ì‹œí—˜',
            r'([ê°€-í£]+ê³¼)\s*ì‹œí—˜',
        ]
        
        for pattern in subject_patterns:
            match = re.search(pattern, text)
            if match:
                metadata.subject = match.group(1)
                break
        
        # ì œëª© ì¶”ì¶œ (ì²« ë²ˆì§¸ ì¤„ì—ì„œ ì¶”ì¶œ)
        lines = text.split('\n')
        for line in lines[:10]:  # ì²« 10ì¤„ ë‚´ì—ì„œ ì°¾ê¸°
            line = line.strip()
            if line and len(line) > 10:
                metadata.title = line
                break
        
        return metadata

    def _extract_questions(self, text: str) -> List[ParsedQuestion]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì œì™€ ì„ íƒì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        questions = []
        
        # ë¬¸ì œ ë¶„í• 
        question_splits = self.question_pattern.split(text)
        
        for i in range(1, len(question_splits), 2):
            try:
                question_num = int(question_splits[i])
                question_text = question_splits[i + 1]
                
                # ë¬¸ì œ ë‚´ìš©ê³¼ ì„ íƒì§€ ë¶„ë¦¬
                content, options = self._parse_question_content(question_text)
                
                if content and options:
                    question = ParsedQuestion(
                        number=question_num,
                        content=content.strip(),
                        options=options
                    )
                    questions.append(question)
                    
            except (ValueError, IndexError) as e:
                logger.warning(f"ë¬¸ì œ {i//2 + 1} íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                continue
        
        return questions

    def _parse_question_content(self, text: str) -> Tuple[str, Dict[str, str]]:
        """ë¬¸ì œ í…ìŠ¤íŠ¸ì—ì„œ ë‚´ìš©ê³¼ ì„ íƒì§€ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤."""
        lines = text.split('\n')
        content_lines = []
        options = {}
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ì„ íƒì§€ íŒ¨í„´ í™•ì¸
            option_found = False
            for pattern in self.option_patterns:
                match = pattern.match(line)
                if match:
                    option_key = self._normalize_option_key(match.group(1))
                    option_value = match.group(2).strip()
                    options[option_key] = option_value
                    option_found = True
                    break
            
            if not option_found:
                content_lines.append(line)
        
        content = ' '.join(content_lines).strip()
        
        # ë¬¸ì œ ë‚´ìš©ì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
        content = re.sub(r'ë‹¤ìŒ.*?ì¤‘.*?ê²ƒì€', 'ë‹¤ìŒ ì¤‘ ì ì ˆí•œ ê²ƒì€', content)
        content = re.sub(r'\s+', ' ', content)
        
        return content, options

    def _normalize_option_key(self, key: str) -> str:
        """ì„ íƒì§€ í‚¤ë¥¼ í‘œì¤€í™”í•©ë‹ˆë‹¤."""
        # â‘  â†’ 1, â‘¡ â†’ 2 ë“±ìœ¼ë¡œ ë³€í™˜
        if key in 'â‘ â‘¡â‘¢â‘£â‘¤':
            return str(ord(key) - ord('â‘ ') + 1)
        # ê°€ â†’ 1, ë‚˜ â†’ 2 ë“±ìœ¼ë¡œ ë³€í™˜
        if key in 'ê°€ë‚˜ë‹¤ë¼ë§ˆ':
            return str(ord(key) - ord('ê°€') + 1)
        return key

    def _extract_answers(self, text: str) -> Dict[int, str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì •ë‹µì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        answers = {}
        
        # ì •ë‹µ ì„¹ì…˜ ì°¾ê¸°
        answer_section_match = re.search(r'ì •ë‹µ.*?(?=\n\n|\Z)', text, re.DOTALL | re.IGNORECASE)
        if answer_section_match:
            answer_section = answer_section_match.group(0)
            
            # ê° ë¬¸ì œë³„ ì •ë‹µ ì¶”ì¶œ
            answer_matches = re.findall(r'(\d+)[\.\)]\s*([â‘ -â‘¤]|\d+|[ê°€-ë§ˆ])', answer_section)
            for match in answer_matches:
                question_num = int(match[0])
                answer_key = self._normalize_option_key(match[1])
                answers[question_num] = answer_key
        
        return answers

    def _map_answers_to_questions(self, questions: List[ParsedQuestion], answers: Dict[int, str]):
        """ì •ë‹µì„ í•´ë‹¹ ë¬¸ì œì— ë§¤í•‘í•©ë‹ˆë‹¤."""
        for question in questions:
            if question.number in answers:
                question.answer = answers[question.number]

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
parser_service = PDFParserService()
```

### 4. API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„

**`app/api/endpoints/parser.py`**
```python
import os
import uuid
import logging
from fastapi import APIRouter, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from app.services.parser_service import parser_service
from app.services.file_service import file_service
from app.models.response_models import ApiResponse
from app.core.config import settings

router = APIRouter()
logger = logging.getLogger(__name__)

@router.post("/parse")
async def parse_file(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...)
):
    """PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  íŒŒì‹±í•©ë‹ˆë‹¤."""
    
    # íŒŒì¼ ê²€ì¦
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(
            status_code=400,
            detail="PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
    
    if file.size > settings.MAX_FILE_SIZE:
        raise HTTPException(
            status_code=413,
            detail=f"íŒŒì¼ í¬ê¸°ëŠ” {settings.MAX_FILE_SIZE // 1024 // 1024}MBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    
    try:
        # ì„ì‹œ íŒŒì¼ ì €ì¥
        file_id = str(uuid.uuid4())
        file_path = await file_service.save_temp_file(file, file_id)
        
        # íŒŒì‹± ì‹¤í–‰
        result = await parser_service.parse_pdf(file_path)
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        background_tasks.add_task(file_service.cleanup_temp_file, file_path)
        
        return ApiResponse(
            success=True,
            data=result,
            message="íŒŒì¼ íŒŒì‹± ì„±ê³µ"
        )
        
    except Exception as e:
        logger.error(f"íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(
            status_code=500,
            content=ApiResponse(
                success=False,
                error="íŒŒì¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                details=str(e)
            ).dict()
        )

@router.post("/parse-async")
async def parse_file_async(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...)
):
    """ë¹„ë™ê¸° PDF íŒŒì‹± (ëŒ€ìš©ëŸ‰ íŒŒì¼ìš©)"""
    
    # íŒŒì¼ ê²€ì¦ (ë™ì¼)
    
    try:
        # ì‘ì—… ID ìƒì„±
        job_id = str(uuid.uuid4())
        
        # íŒŒì¼ ì €ì¥
        file_path = await file_service.save_temp_file(file, job_id)
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì‹± ì‹¤í–‰
        background_tasks.add_task(
            process_file_async, 
            job_id, 
            file_path
        )
        
        return ApiResponse(
            success=True,
            data={"job_id": job_id},
            message="íŒŒì‹± ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
        
    except Exception as e:
        logger.error(f"ë¹„ë™ê¸° íŒŒì‹± ì‹œì‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

async def process_file_async(job_id: str, file_path: str):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        # íŒŒì‹± ì‹¤í–‰
        result = await parser_service.parse_pdf(file_path)
        
        # ê²°ê³¼ ì €ì¥ (DB ë˜ëŠ” ìºì‹œ)
        await file_service.save_parse_result(job_id, result)
        
    except Exception as e:
        logger.error(f"ë¹„ë™ê¸° íŒŒì‹± ì˜¤ë¥˜ (job_id: {job_id}): {str(e)}")
        await file_service.save_parse_error(job_id, str(e))
    
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        await file_service.cleanup_temp_file(file_path)
```

### 5. íŒŒì¼ ì„œë¹„ìŠ¤ êµ¬í˜„

**`app/services/file_service.py`**
```python
import os
import aiofiles
import tempfile
from pathlib import Path
from fastapi import UploadFile
from app.core.config import settings

class FileService:
    def __init__(self):
        self.temp_dir = Path(settings.TEMP_DIR)
        self.temp_dir.mkdir(exist_ok=True)

    async def save_temp_file(self, file: UploadFile, file_id: str) -> str:
        """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤."""
        file_extension = Path(file.filename).suffix
        temp_filename = f"{file_id}{file_extension}"
        temp_path = self.temp_dir / temp_filename
        
        async with aiofiles.open(temp_path, 'wb') as f:
            content = await file.read()
            await f.write(content)
        
        return str(temp_path)

    async def cleanup_temp_file(self, file_path: str):
        """ì„ì‹œ íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
        except Exception as e:
            # ë¡œê¹…ë§Œ í•˜ê³  ì—ëŸ¬ëŠ” ë¬´ì‹œ
            import logging
            logging.getLogger(__name__).warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
file_service = FileService()
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‘ì„±

**`tests/test_parser.py`**
```python
import pytest
from app.services.parser_service import PDFParserService

@pytest.fixture
def parser():
    return PDFParserService()

@pytest.fixture
def sample_pdf_path():
    return "tests/test_files/sample_exam.pdf"

@pytest.mark.asyncio
async def test_parse_pdf_success(parser, sample_pdf_path):
    """PDF íŒŒì‹± ì„±ê³µ í…ŒìŠ¤íŠ¸"""
    result = await parser.parse_pdf(sample_pdf_path)
    
    assert result is not None
    assert len(result.questions) > 0
    assert result.questions[0].number == 1
    assert result.questions[0].content is not None
    assert len(result.questions[0].options) > 0

@pytest.mark.asyncio 
async def test_question_extraction(parser):
    """ë¬¸ì œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    sample_text = """
    1. ë‹¤ìŒ ì¤‘ ë¬¼ë¦¬ì¹˜ë£Œì‚¬ì˜ ì—­í• ì€?
    1) ì§„ë‹¨
    2) ì¬í™œ
    3) ì²˜ë°©
    4) ìˆ˜ìˆ 
    
    2. ê·¼ìœ¡ì˜ ê¸°ëŠ¥ì´ ì•„ë‹Œ ê²ƒì€?
    1) ì›€ì§ì„
    2) ì§€ì§€
    3) ì†Œí™”
    4) ì—´ìƒì‚°
    """
    
    questions = parser._extract_questions(sample_text)
    
    assert len(questions) == 2
    assert questions[0].number == 1
    assert "ë¬¼ë¦¬ì¹˜ë£Œì‚¬" in questions[0].content
    assert "1" in questions[0].options
    assert "2" in questions[0].options
```

## ğŸ” ë””ë²„ê¹… íŒ

### 1. ë¡œê¹… í™œìš©
```python
import logging

# ìƒì„¸ ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# íŒŒì‹± ê³¼ì •ì—ì„œ ì¤‘ê°„ ê²°ê³¼ ë¡œê¹…
logger.debug(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
logger.debug(f"ì°¾ì€ ë¬¸ì œ ìˆ˜: {len(questions)}")
```

### 2. ì •ê·œí‘œí˜„ì‹ í…ŒìŠ¤íŠ¸
```python
import re

# íŒ¨í„´ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
def test_regex_pattern():
    text = "1. ë¬¸ì œë‚´ìš©\n1) ì„ íƒì§€1\n2) ì„ íƒì§€2"
    pattern = re.compile(r'^(\d+)[\.\)]', re.MULTILINE)
    matches = pattern.findall(text)
    print(f"ë§¤ì¹˜ ê²°ê³¼: {matches}")

# ì˜¨ë¼ì¸ ì •ê·œí‘œí˜„ì‹ í…ŒìŠ¤í„° í™œìš©: regex101.com
```

### 3. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²€ì¦
```python
# ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í™•ì¸
with open('extracted_text.txt', 'w', encoding='utf-8') as f:
    f.write(extracted_text)

# íŠ¹ì • í˜ì´ì§€ë§Œ ì¶”ì¶œí•´ì„œ í…ŒìŠ¤íŠ¸
page_text = pdf.pages[0].extract_text()
```

## ğŸš€ ì„±ëŠ¥ ìµœì í™”

### 1. ë¹„ë™ê¸° ì²˜ë¦¬
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

# CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
async def parse_pdf_async(file_path: str):
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor() as executor:
        result = await loop.run_in_executor(
            executor, 
            _parse_pdf_sync, 
            file_path
        )
    return result
```

### 2. ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
import gc

# ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ í›„ ë©”ëª¨ë¦¬ í•´ì œ
def process_large_pdf():
    # ... ì²˜ë¦¬ ë¡œì§
    gc.collect()  # ëª…ì‹œì  ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
```

### 3. ìºì‹± í™œìš©
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def extract_metadata_cached(text_hash: str, text: str):
    return extract_metadata(text)
```

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. **AI í•´ì„¤ ìƒì„±**: OpenAI APIë¥¼ í™œìš©í•œ ìë™ í•´ì„¤ ìƒì„±
2. **ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™**: íŒŒì‹± ê²°ê³¼ ì˜êµ¬ ì €ì¥
3. **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ì²˜ë¦¬
4. **API ë¬¸ì„œí™”**: Swagger UI ìë™ ìƒì„±
5. **ëª¨ë‹ˆí„°ë§**: ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ë° ëª¨ë‹ˆí„°ë§

ê° ë‹¨ê³„ë³„ë¡œ ì ì§„ì ìœ¼ë¡œ ê°œë°œí•´ ë‚˜ê°€ì„¸ìš”! 